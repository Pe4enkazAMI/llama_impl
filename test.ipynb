{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model.feedforward import FeedForwardLayer\n",
    "import torch\n",
    "from model.attention import MultiHeadAttention\n",
    "from model.posencoding import RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffl = FeedForwardLayer(emb_dim=256, exp_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.randn(size=(32, 10, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(input_dim=256, emb_dim=256, num_head=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, at = mha(batch, return_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1693dd110>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(at[0, 0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(10).float()\n",
    "b = torch.ones(10).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7., 7., 7., 7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8., 8., 8., 8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"i,j -> ij\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4., 4., 4., 4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7., 7., 7., 7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8., 8., 8., 8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9., 9., 9., 9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1, 1) @ b.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyStories_all_dat 100%[===================>]   1,50G  4,77MB/s    in 5m 37s  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "rope = RoPE(dim=256, base=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 128]) torch.Size([32, 10, 128])\n",
      "torch.Size([10, 256])\n",
      "torch.Size([32, 10, 128]) torch.Size([32, 10, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.decoder import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Decoder(256, 2, 2, 2, **{\"use_rope\": True, \"rotary_base\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-08 03:21:06--  https://raw.githubusercontent.com/google/sentencepiece/master/data/botchan.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 278779 (272K) [text/plain]\n",
      "Saving to: ‘botchan.txt’\n",
      "\n",
      "botchan.txt         100%[===================>] 272,25K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2023-11-08 03:21:06 (2,13 MB/s) - ‘botchan.txt’ saved [278779/278779]\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/Users/bayesian_monster/llama/TinyStories.txt --model_prefix=llama --vocab_size=2000 --model_type=bpe\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /Users/bayesian_monster/llama/TinyStories.txt\n",
      "  input_format: \n",
      "  model_prefix: llama\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(352) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(184) LOG(INFO) Loading corpus: /Users/bayesian_monster/llama/TinyStories.txt\n",
      "trainer_interface.cc(408) LOG(INFO) Loaded all 315657 sentences\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(429) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(538) LOG(INFO) all chars count=77423730\n",
      "trainer_interface.cc(549) LOG(INFO) Done: 99.9585% characters are covered.\n",
      "trainer_interface.cc(559) LOG(INFO) Alphabet size=53\n",
      "trainer_interface.cc(560) LOG(INFO) Final character coverage=0.999585\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 315545 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 315545\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 63794\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2244383 min_freq=1\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=471718 size=20 all=1486 active=1432 piece=▁l\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=293676 size=40 all=2255 active=2201 piece=▁g\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=178016 size=60 all=3084 active=3030 piece=▁u\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=147195 size=80 all=3607 active=3553 piece=pp\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=116834 size=100 all=4028 active=3974 piece=▁I\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=115834 min_freq=3275\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=96936 size=120 all=4375 active=1333 piece=ad\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=79905 size=140 all=4724 active=1682 piece=▁lo\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=68359 size=160 all=5259 active=2217 piece=ide\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=57534 size=180 all=5606 active=2564 piece=ore\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=49655 size=200 all=6020 active=2978 piece=▁Tom\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=49089 min_freq=3455\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=42147 size=220 all=6312 active=1288 piece=ul\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=36959 size=240 all=6723 active=1699 piece=▁F\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=34058 size=260 all=7056 active=2032 piece=▁sc\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=29826 size=280 all=7308 active=2284 piece=▁would\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=27462 size=300 all=7578 active=2554 piece=dd\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=27373 min_freq=3174\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=24681 size=320 all=7912 active=1307 piece=▁wal\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=22866 size=340 all=8111 active=1506 piece=ble\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=21748 size=360 all=8393 active=1788 piece=▁thought\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=19953 size=380 all=8675 active=2070 piece=▁about\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=18419 size=400 all=8900 active=2295 piece=hat\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=18419 min_freq=2788\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=16827 size=420 all=9212 active=1303 piece=▁dad\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=15717 size=440 all=9503 active=1594 piece=▁po\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=14791 size=460 all=9794 active=1885 piece=▁water\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=13824 size=480 all=10114 active=2205 piece=▁many\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=12835 size=500 all=10296 active=2387 piece=▁surpr\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=12833 min_freq=2426\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=12170 size=520 all=10468 active=1171 piece=ma\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=11433 size=540 all=10671 active=1374 piece=▁list\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=10918 size=560 all=10834 active=1537 piece=▁never\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=10209 size=580 all=11026 active=1729 piece=▁animals\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=9784 size=600 all=11167 active=1870 piece=▁flew\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=9697 min_freq=2166\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=9211 size=620 all=11284 active=1118 piece=ady\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8849 size=640 all=11445 active=1279 piece=ool\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8545 size=660 all=11550 active=1384 piece=▁still\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8162 size=680 all=11681 active=1515 piece=▁forest\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7921 size=700 all=11811 active=1645 piece=ip\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=7919 min_freq=1926\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7630 size=720 all=11928 active=1062 piece=unny\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7322 size=740 all=12137 active=1271 piece=▁cake\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7099 size=760 all=12274 active=1408 piece=▁remember\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6672 size=780 all=12390 active=1524 piece=▁place\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6389 size=800 all=12533 active=1667 piece=▁yummy\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=6385 min_freq=1690\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6133 size=820 all=12734 active=1202 piece=ting\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5856 size=840 all=12895 active=1363 piece=▁mon\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5638 size=860 all=13006 active=1474 piece=▁adventure\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5397 size=880 all=13147 active=1615 piece=▁sometimes\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5128 size=900 all=13211 active=1679 piece=▁pain\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=5128 min_freq=1516\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5018 size=920 all=13354 active=1137 piece=▁our\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4873 size=940 all=13505 active=1288 piece=▁buy\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4759 size=960 all=13613 active=1396 piece=▁wear\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4564 size=980 all=13672 active=1455 piece=llow\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4439 size=1000 all=13756 active=1539 piece=▁noticed\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=4437 min_freq=1378\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4259 size=1020 all=13911 active=1156 piece=▁bag\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4136 size=1040 all=13975 active=1220 piece=▁please\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4030 size=1060 all=14051 active=1296 piece=▁listened\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3927 size=1080 all=14125 active=1370 piece=▁Tw\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3764 size=1100 all=14188 active=1433 piece=▁Tweet\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=3764 min_freq=1244\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3630 size=1120 all=14247 active=1058 piece=▁fair\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3529 size=1140 all=14274 active=1085 piece=▁left\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3430 size=1160 all=14346 active=1157 piece=▁close\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3354 size=1180 all=14431 active=1242 piece=▁owl\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3239 size=1200 all=14557 active=1368 piece=▁shout\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=3237 min_freq=1153\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3170 size=1220 all=14617 active=1058 piece=▁count\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3057 size=1240 all=14716 active=1157 piece=▁visit\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2979 size=1260 all=14813 active=1254 piece=▁crying\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2886 size=1280 all=14929 active=1370 piece=▁sister\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2822 size=1300 all=15051 active=1492 piece=illed\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2819 min_freq=1030\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2726 size=1320 all=15171 active=1112 piece=ance\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2661 size=1340 all=15240 active=1181 piece=▁Bobo\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2587 size=1360 all=15308 active=1249 piece=▁paint\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2535 size=1380 all=15432 active=1373 piece=▁All\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2440 size=1400 all=15587 active=1528 piece=▁gif\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2440 min_freq=922\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2368 size=1420 all=15735 active=1147 piece=ze\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2329 size=1440 all=15850 active=1262 piece=▁snack\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2279 size=1460 all=15908 active=1320 piece=▁gu\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2203 size=1480 all=15946 active=1358 piece=gged\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2130 size=1500 all=16021 active=1433 piece=▁que\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2127 min_freq=855\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2070 size=1520 all=16139 active=1116 piece=▁sharing\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2024 size=1540 all=16286 active=1263 piece=bor\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1985 size=1560 all=16407 active=1384 piece=ung\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1951 size=1580 all=16549 active=1526 piece=▁basket\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1889 size=1600 all=16662 active=1639 piece=▁belie\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1887 min_freq=795\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1834 size=1620 all=16813 active=1147 piece=▁turns\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1763 size=1640 all=16842 active=1176 piece=▁Ch\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1731 size=1660 all=16928 active=1262 piece=▁pocket\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1701 size=1680 all=16965 active=1299 piece=▁filled\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1663 size=1700 all=17030 active=1364 piece=▁butt\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1662 min_freq=742\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1638 size=1720 all=17066 active=1034 piece=ining\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1609 size=1740 all=17128 active=1096 piece=Maybe\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1557 size=1760 all=17213 active=1181 piece=iskers\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1501 size=1780 all=17282 active=1250 piece=▁later\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1467 size=1800 all=17320 active=1288 piece=▁nut\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1464 min_freq=696\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1433 size=1820 all=17360 active=1037 piece=ital\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1404 size=1840 all=17441 active=1118 piece=▁cave\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1382 size=1860 all=17478 active=1155 piece=ially\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1367 size=1880 all=17520 active=1197 piece=▁afraid\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1345 size=1900 all=17601 active=1278 piece=▁drawing\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1344 min_freq=655\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1315 size=1920 all=17607 active=1007 piece=▁veget\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1295 size=1940 all=17635 active=1035 piece=pa\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: llama.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: llama.vocab\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bayesian_monster/llama/test.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spm\u001b[39m.\u001b[39;49mSentencePieceTrainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m\"\u001b[39;49m\u001b[39m--input=/Users/bayesian_monster/llama/TinyStories.txt --model_prefix=llama --vocab_size=2000 --model_type=bpe\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(arg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, logstream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[39mwith\u001b[39;00m _LogStream(ostream\u001b[39m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[39m.\u001b[39;49m_Train(arg\u001b[39m=\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/sentencepiece/__init__.py:945\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(arg) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 945\u001b[0m   \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39;49m_TrainFromString(arg)\n\u001b[1;32m    947\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode\u001b[39m(value):\n\u001b[1;32m    948\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Encode value to CSV..\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/sentencepiece/__init__.py:923\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromString\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_TrainFromString\u001b[39m(arg):\n\u001b[0;32m--> 923\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceTrainer__TrainFromString(arg)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(\"--input=/Users/bayesian_monster/llama/TinyStories.txt --model_prefix=llama --vocab_size=2000 --model_type=bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"llama.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁T', 'est']\n",
      "[471, 601]\n"
     ]
    }
   ],
   "source": [
    "print(sp.encode_as_pieces(\"Test\"))\n",
    "print(sp.EncodeAsIds(\"Test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [\"test\"] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601],\n",
       " [434, 601]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.EncodeAsIds(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/Users/bayesian_monster/llama/TinyStories_all_data/data00.json\", mode=\"r\") as f:\n",
    "    index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story = []\n",
    "# with open(\"/Users/bayesian_monster/llama/TinyStories.txt\", \"w\") as f:\n",
    "#     for i in range(len(index)):\n",
    "#         f.write(index[i][\"story\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer.tokenizer import Tokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz = Tokenizer(\"/Users/bayesian_monster/llama/TinyStoriesV3-GPT4-train.txt\", 32000, \"llama\", \"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz.load(\"/Users/bayesian_monster/llama/llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bayesian_monster/llama/test.ipynb Cell 29\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     encoded \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(tknz\u001b[39m.\u001b[39;49mencode(row))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     path \u001b[39m=\u001b[39m train_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     np\u001b[39m.\u001b[39msave(path, encoded)\n",
      "File \u001b[0;32m~/llama/tokenizer/tokenizer.py:21\u001b[0m, in \u001b[0;36mTokenizer.encode\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, string):\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mEncode(string)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/sentencepiece/__init__.py:528\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Encode\u001b[0;34m(self, input, out_type, add_bos, add_eos, reverse, emit_unk_piece, enable_sampling, nbest_size, alpha, num_threads)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_EncodeAsImmutableProtoBatch(\u001b[39minput\u001b[39m, num_threads, enable_sampling, nbest_size,\n\u001b[1;32m    525\u001b[0m                                              alpha, add_bos, add_eos, reverse, emit_unk_piece)\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m out_type \u001b[39mis\u001b[39;00m \u001b[39mint\u001b[39m:\n\u001b[0;32m--> 528\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_EncodeAsIds(\u001b[39minput\u001b[39;49m, enable_sampling, nbest_size,\n\u001b[1;32m    529\u001b[0m                            alpha, add_bos, add_eos, reverse, emit_unk_piece)\n\u001b[1;32m    530\u001b[0m \u001b[39mif\u001b[39;00m out_type \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    531\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_EncodeAsPieces(\u001b[39minput\u001b[39m, enable_sampling, nbest_size,\n\u001b[1;32m    532\u001b[0m                               alpha, add_bos, add_eos, reverse, emit_unk_piece)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/sentencepiece/__init__.py:313\u001b[0m, in \u001b[0;36mSentencePieceProcessor._EncodeAsIds\u001b[0;34m(self, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_EncodeAsIds\u001b[39m(\u001b[39mself\u001b[39m, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece):\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceProcessor__EncodeAsIds(\u001b[39mself\u001b[39;49m, text, enable_sampling, nbest_size, alpha, add_bos, add_eos, reverse, emit_unk_piece)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "train_path = Path(\"/Users/bayesian_monster/llama/train_files\")\n",
    "val_path = Path(\"/Users/bayesian_monster/llama/val_files\")\n",
    "\n",
    "with open(\"/Users/bayesian_monster/llama/TinyStoriesV3-GPT4-train.txt\", \"r\") as file:\n",
    "    i = 0\n",
    "    for row in file:\n",
    "        encoded = np.array(tknz.encode(row))\n",
    "        path = train_path / f\"{i + 1}.npy\"\n",
    "        np.save(path, encoded)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SentencePieceProcessor' object has no attribute 'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/bayesian_monster/llama/test.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tknz\u001b[39m.\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SentencePieceProcessor' object has no attribute 'pad'"
     ]
    }
   ],
   "source": [
    "tknz.tokenizer.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tknz.encode([\"This is me\", \"asss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1154, 211, 275, 2], [1, 170, 289, 2]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pad_sequence(map(lambda x: torch.tensor(x), a)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Embedding(num_embeddings=50, embedding_dim=100, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1154, 211, 275, 2], [1, 170, 289, 2, 0]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is me', 'asss ⁇ ']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknz.decode(x.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bayesian_monster/llama/test.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bayesian_monster/llama/test.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m l(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/bayesian_monster/llama/TinyStories.txt\", \"r\") as f:\n",
    "    c = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import LLaMaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/Users/bayesian_monster/llama/TinyStories.txt --model_prefix=llama --vocab_size=2000 --model_type=bpe --user_defined_symbols=[PAD]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /Users/bayesian_monster/llama/TinyStories.txt\n",
      "  input_format: \n",
      "  model_prefix: llama\n",
      "  model_type: BPE\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [PAD]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(352) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(184) LOG(INFO) Loading corpus: /Users/bayesian_monster/llama/TinyStories.txt\n",
      "trainer_interface.cc(408) LOG(INFO) Loaded all 315657 sentences\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(424) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(429) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(538) LOG(INFO) all chars count=77423730\n",
      "trainer_interface.cc(549) LOG(INFO) Done: 99.9585% characters are covered.\n",
      "trainer_interface.cc(559) LOG(INFO) Alphabet size=53\n",
      "trainer_interface.cc(560) LOG(INFO) Final character coverage=0.999585\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 315545 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 315545\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 63794\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2244383 min_freq=1\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=471718 size=20 all=1486 active=1432 piece=▁l\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=293676 size=40 all=2255 active=2201 piece=▁g\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=178016 size=60 all=3084 active=3030 piece=▁u\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=147195 size=80 all=3607 active=3553 piece=pp\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=116834 size=100 all=4028 active=3974 piece=▁I\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=115834 min_freq=3275\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=96936 size=120 all=4375 active=1333 piece=ad\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=79905 size=140 all=4724 active=1682 piece=▁lo\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=68359 size=160 all=5259 active=2217 piece=ide\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=57534 size=180 all=5606 active=2564 piece=ore\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=49655 size=200 all=6020 active=2978 piece=▁Tom\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=49089 min_freq=3455\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=42147 size=220 all=6312 active=1288 piece=ul\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=36959 size=240 all=6723 active=1699 piece=▁F\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=34058 size=260 all=7056 active=2032 piece=▁sc\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=29826 size=280 all=7308 active=2284 piece=▁would\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=27462 size=300 all=7578 active=2554 piece=dd\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=27373 min_freq=3174\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=24681 size=320 all=7912 active=1307 piece=▁wal\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=22866 size=340 all=8111 active=1506 piece=ble\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=21748 size=360 all=8393 active=1788 piece=▁thought\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=19953 size=380 all=8675 active=2070 piece=▁about\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=18419 size=400 all=8900 active=2295 piece=hat\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=18419 min_freq=2788\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=16827 size=420 all=9212 active=1303 piece=▁dad\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=15717 size=440 all=9503 active=1594 piece=▁po\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=14791 size=460 all=9794 active=1885 piece=▁water\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=13824 size=480 all=10114 active=2205 piece=▁many\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=12835 size=500 all=10296 active=2387 piece=▁surpr\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=12833 min_freq=2426\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=12170 size=520 all=10468 active=1171 piece=ma\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=11433 size=540 all=10671 active=1374 piece=▁list\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=10918 size=560 all=10834 active=1537 piece=▁never\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=10209 size=580 all=11026 active=1729 piece=▁animals\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=9784 size=600 all=11167 active=1870 piece=▁flew\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=9697 min_freq=2166\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=9211 size=620 all=11284 active=1118 piece=ady\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8849 size=640 all=11445 active=1279 piece=ool\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8545 size=660 all=11550 active=1384 piece=▁still\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=8162 size=680 all=11681 active=1515 piece=▁forest\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7921 size=700 all=11811 active=1645 piece=ip\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=7919 min_freq=1926\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7630 size=720 all=11928 active=1062 piece=unny\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7322 size=740 all=12137 active=1271 piece=▁cake\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=7099 size=760 all=12274 active=1408 piece=▁remember\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6672 size=780 all=12390 active=1524 piece=▁place\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6389 size=800 all=12533 active=1667 piece=▁yummy\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=6385 min_freq=1690\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=6133 size=820 all=12734 active=1202 piece=ting\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5856 size=840 all=12895 active=1363 piece=▁mon\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5638 size=860 all=13006 active=1474 piece=▁adventure\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5397 size=880 all=13147 active=1615 piece=▁sometimes\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5128 size=900 all=13211 active=1679 piece=▁pain\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=5128 min_freq=1516\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=5018 size=920 all=13354 active=1137 piece=▁our\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4873 size=940 all=13505 active=1288 piece=▁buy\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4759 size=960 all=13613 active=1396 piece=▁wear\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4564 size=980 all=13672 active=1455 piece=llow\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4439 size=1000 all=13756 active=1539 piece=▁noticed\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=4437 min_freq=1378\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4259 size=1020 all=13911 active=1156 piece=▁bag\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4136 size=1040 all=13975 active=1220 piece=▁please\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=4030 size=1060 all=14051 active=1296 piece=▁listened\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3927 size=1080 all=14125 active=1370 piece=▁Tw\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3764 size=1100 all=14188 active=1433 piece=▁Tweet\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=3764 min_freq=1244\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3630 size=1120 all=14247 active=1058 piece=▁fair\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3529 size=1140 all=14274 active=1085 piece=▁left\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3430 size=1160 all=14346 active=1157 piece=▁close\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3354 size=1180 all=14431 active=1242 piece=▁owl\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3239 size=1200 all=14557 active=1368 piece=▁shout\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=3237 min_freq=1153\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3170 size=1220 all=14617 active=1058 piece=▁count\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=3057 size=1240 all=14716 active=1157 piece=▁visit\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2979 size=1260 all=14813 active=1254 piece=▁crying\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2886 size=1280 all=14929 active=1370 piece=▁sister\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2822 size=1300 all=15051 active=1492 piece=illed\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2819 min_freq=1030\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2726 size=1320 all=15171 active=1112 piece=ance\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2661 size=1340 all=15240 active=1181 piece=▁Bobo\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2587 size=1360 all=15308 active=1249 piece=▁paint\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2535 size=1380 all=15432 active=1373 piece=▁All\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2440 size=1400 all=15587 active=1528 piece=▁gif\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2440 min_freq=922\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2368 size=1420 all=15735 active=1147 piece=ze\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2329 size=1440 all=15850 active=1262 piece=▁snack\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2279 size=1460 all=15908 active=1320 piece=▁gu\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2203 size=1480 all=15946 active=1358 piece=gged\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2130 size=1500 all=16021 active=1433 piece=▁que\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=2127 min_freq=855\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2070 size=1520 all=16139 active=1116 piece=▁sharing\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=2024 size=1540 all=16286 active=1263 piece=bor\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1985 size=1560 all=16407 active=1384 piece=ung\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1951 size=1580 all=16549 active=1526 piece=▁basket\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1889 size=1600 all=16662 active=1639 piece=▁belie\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1887 min_freq=795\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1834 size=1620 all=16813 active=1147 piece=▁turns\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1763 size=1640 all=16842 active=1176 piece=▁Ch\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1731 size=1660 all=16928 active=1262 piece=▁pocket\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1701 size=1680 all=16965 active=1299 piece=▁filled\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1663 size=1700 all=17030 active=1364 piece=▁butt\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1662 min_freq=742\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1638 size=1720 all=17066 active=1034 piece=ining\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1609 size=1740 all=17128 active=1096 piece=Maybe\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1557 size=1760 all=17213 active=1181 piece=iskers\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1501 size=1780 all=17282 active=1250 piece=▁later\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1467 size=1800 all=17320 active=1288 piece=▁nut\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1464 min_freq=696\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1433 size=1820 all=17360 active=1037 piece=ital\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1404 size=1840 all=17441 active=1118 piece=▁cave\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1382 size=1860 all=17478 active=1155 piece=ially\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1367 size=1880 all=17520 active=1197 piece=▁afraid\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1345 size=1900 all=17601 active=1278 piece=▁drawing\n",
      "bpe_model_trainer.cc(160) LOG(INFO) Updating active symbols. max_freq=1344 min_freq=655\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1315 size=1920 all=17607 active=1007 piece=▁veget\n",
      "bpe_model_trainer.cc(269) LOG(INFO) Added: freq=1295 size=1940 all=17635 active=1035 piece=pa\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: llama.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: llama.vocab\n"
     ]
    }
   ],
   "source": [
    "dt = LLaMaDataset(\"TinyStories.txt\", \"/Users/bayesian_monster/llama/\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.vocab.decode([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 40, 2956, 2]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknz.encode(\"sas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3360,  2.4695],\n",
       "        [-1.3090,  0.3886],\n",
       "        [-0.0666, -1.9801],\n",
       "        [ 0.4612, -1.0595],\n",
       "        [ 0.1188, -1.0825],\n",
       "        [ 0.9645, -1.5288],\n",
       "        [ 0.2070,  0.8887],\n",
       "        [-0.0441, -0.1561],\n",
       "        [ 1.0957, -0.7865],\n",
       "        [ 1.1216, -0.6164],\n",
       "        [-0.0540, -0.6910],\n",
       "        [-1.0713, -0.7035],\n",
       "        [-0.2244, -0.9473],\n",
       "        [ 0.9645, -1.5288],\n",
       "        [ 0.7791, -0.2654],\n",
       "        [ 0.6706,  0.1540],\n",
       "        [ 0.9800,  0.2608],\n",
       "        [-0.5306, -1.3335],\n",
       "        [ 1.8462, -2.4400],\n",
       "        [ 1.6832,  0.5351],\n",
       "        [ 0.6030,  0.9475],\n",
       "        [ 0.2196, -0.8541],\n",
       "        [-0.1392,  0.0823],\n",
       "        [ 1.6832,  0.5351],\n",
       "        [ 0.2797, -0.1501],\n",
       "        [ 0.9645, -1.5288],\n",
       "        [-0.3360,  2.4695],\n",
       "        [-0.4890, -1.2180],\n",
       "        [ 1.0957, -0.7865],\n",
       "        [-0.1444,  1.4621],\n",
       "        [-1.0713, -0.7035],\n",
       "        [ 0.2797, -0.1501],\n",
       "        [ 0.9645, -1.5288],\n",
       "        [-0.4305,  0.7287],\n",
       "        [ 1.4685,  0.7015],\n",
       "        [ 2.2767, -1.8426],\n",
       "        [ 1.0957, -0.7865],\n",
       "        [-1.0713, -0.7035],\n",
       "        [ 0.2196, -0.8541],\n",
       "        [-1.3090,  0.3886],\n",
       "        [-0.3777, -1.5384],\n",
       "        [ 2.2767, -1.8426],\n",
       "        [ 0.6563,  0.9879],\n",
       "        [-1.0713, -0.7035],\n",
       "        [ 0.2797, -0.1501],\n",
       "        [ 0.9645, -1.5288]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(dt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "jopa = DataLoader(dt, batch_size=10, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Embedding(num_embeddings=3000, embedding_dim=2, padding_idx=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4028,  1.1555],\n",
       "        [-0.4028,  1.1555]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(torch.ones(2).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': tensor([[   1,   58,  815,  ...,    3,    3,    2],\n",
       "         [   1,   36,  120,  ...,    3,    3,    2],\n",
       "         [   1, 1150,  324,  ...,    3,    3,    2],\n",
       "         ...,\n",
       "         [   1, 1150,  324,  ...,  269, 1963,    2],\n",
       "         [   1,  804, 1805,  ...,    3,    3,    2],\n",
       "         [   1,  461, 1969,  ...,    3,    3,    2]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(jopa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [torch.cat([torch.tensor([1]), a])] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pad_sequence(s, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack([s, torch.ones(2)[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
